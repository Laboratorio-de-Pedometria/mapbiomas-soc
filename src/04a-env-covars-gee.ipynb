{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21890, 38)\n",
      "(17606, 77)\n",
      "The DataFrames are different.\n"
     ]
    }
   ],
   "source": [
    "# title: SoilData - Soil Organic Carbon Stock\n",
    "# subtitle: Prepare environmental covariates\n",
    "# author: Alessandro Samuel-Rosa and Taciara Zborowski Horst\n",
    "# data: 2024 CC-BY\n",
    "\n",
    "# Import necessary libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Identify working directory, saving the path to a variable\n",
    "src_dir = os.getcwd()\n",
    "work_dir = os.path.dirname(src_dir)\n",
    "\n",
    "# Read the TXT file '20_soildata_soc.txt' with the soil data from the 'data' folder\n",
    "# Field separator: tab. Decimal separator: comma\n",
    "file_path = os.path.join(work_dir, 'data', '20_soildata_soc.txt')\n",
    "soildata_df = pd.read_csv(file_path, sep='\\t', low_memory=False)\n",
    "print(soildata_df.shape)\n",
    "\n",
    "# Read the TXT file '04a-febr-data.txt' with the coordinates from the 'data' folder\n",
    "# Field separator: tab. Decimal separator: comma\n",
    "file_path = os.path.join(work_dir, 'data', '04a-febr-data.txt')\n",
    "df2 = pd.read_csv(file_path, sep='\\t', decimal=',', low_memory=False)\n",
    "print(df2.shape)\n",
    "\n",
    "# Compare the two data frames to check if there were changes in the data\n",
    "# Use equals() method to compare the two data frames\n",
    "# The result is a boolean value, True if the data frames are equal, False otherwise\n",
    "# We consider only the following variables in the comparison:\n",
    "# dataset_id, observacao_id, coord_x, coord_y, data_coleta_ano\n",
    "df1 = soildata_df[['dataset_id', 'observacao_id', 'coord_x', 'coord_y', 'data_coleta_ano']]\n",
    "df2 = df2[['dataset_id', 'observacao_id', 'coord_x', 'coord_y', 'data_coleta_ano']]\n",
    "if df1.equals(df2):\n",
    "    print(\"The DataFrames are identical.\")\n",
    "else:\n",
    "    print(\"The DataFrames are different.\")\n",
    "del df1, df2\n",
    "# 17 606 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There should be 9513 events: True \n",
      "There are 9513 events\n"
     ]
    }
   ],
   "source": [
    "# Filter out soil layers without geographic coordinates\n",
    "# coord_x and coord_y are the columns with the geographic coordinates\n",
    "soildata_xy = soildata_df[soildata_df['coord_x'].notnull()]\n",
    "soildata_xy = soildata_xy[soildata_xy['coord_y'].notnull()]\n",
    "\n",
    "# Remove all duplicates based on the following columns:\n",
    "# \"dataset_id\", \"observacao_id\", \"coord_x\", \"coord_y\", \"data_coleta_ano\"\n",
    "# The first occurrence is kept, and the others are removed\n",
    "soildata_xy = soildata_xy[['dataset_id', 'observacao_id', 'coord_x', 'coord_y', 'data_coleta_ano']]\n",
    "soildata_xy = soildata_xy.drop_duplicates()\n",
    "target = 9513\n",
    "print(\n",
    "  'There should be', target, 'events:', target == soildata_xy.shape[0],\n",
    "  '\\nThere are', soildata_xy.shape[0], 'events')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import ee\n",
    "import geemap\n",
    "\n",
    "# Initialize the Earth Engine API\n",
    "ee.Initialize()\n",
    "\n",
    "# Convert DataFrame to Earth Engine Feature Collection\n",
    "soildata_fc = geemap.df_to_ee(soildata_xy, latitude = 'coord_y', longitude = 'coord_x')\n",
    "\n",
    "# Function to split a feature collection (sampling points) into chunks\n",
    "def split_sampling_points(fc, chunk_size):\n",
    "    features = fc.toList(fc.size())\n",
    "    chunks = [features.slice(i, i + chunk_size) for i in range(0, features.size().getInfo(), chunk_size)]\n",
    "    return [ee.FeatureCollection(chunk) for chunk in chunks]\n",
    "\n",
    "# Split the sample points into subsets of 1000 points each\n",
    "# This is necessary to avoid timeout errors\n",
    "chunk_size = 1000\n",
    "soildata_chunks = split_sampling_points(soildata_fc, chunk_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['bdod_0_5cm', 'bdod_15_30cm', 'bdod_5_15cm', 'cfvo_0_5cm',\n",
      "       'cfvo_15_30cm', 'cfvo_5_15cm', 'clay_0_5cm', 'clay_15_30cm',\n",
      "       'clay_5_15cm', 'coord_x', 'coord_y', 'data_coleta_ano', 'dataset_id',\n",
      "       'observacao_id', 'sand_0_5cm', 'sand_15_30cm', 'sand_5_15cm',\n",
      "       'soc_0_5cm', 'soc_15_30cm', 'soc_5_15cm'],\n",
      "      dtype='object')\n",
      "\n",
      "There should be 9513 events: True \n",
      "There are 9513 events\n"
     ]
    }
   ],
   "source": [
    "# Soil Grids 250m v2.0\n",
    "# (this takes about 10 minutes to run)\n",
    "\n",
    "# Soil Grids 250m v2.0: bdod_mean (bulk density)\n",
    "bdod_image = ee.Image(\"projects/soilgrids-isric/bdod_mean\")\n",
    "bdod_image = bdod_image.select(['bdod_0-5cm_mean', 'bdod_5-15cm_mean', 'bdod_15-30cm_mean'])\n",
    "\n",
    "# Soil Grids 250m v2.0: clay_mean (clay content)\n",
    "clay_image = ee.Image(\"projects/soilgrids-isric/clay_mean\")\n",
    "clay_image = clay_image.select(['clay_0-5cm_mean', 'clay_5-15cm_mean', 'clay_15-30cm_mean'])\n",
    "\n",
    "# Soil Grids 250m v2.0: sand_mean (sand content)\n",
    "sand_image = ee.Image(\"projects/soilgrids-isric/sand_mean\")\n",
    "sand_image = sand_image.select(['sand_0-5cm_mean', 'sand_5-15cm_mean', 'sand_15-30cm_mean'])\n",
    "\n",
    "# Soil Grids 250m v2.0: soc_mean (soil organic carbon)\n",
    "soc_image = ee.Image(\"projects/soilgrids-isric/soc_mean\")\n",
    "soc_image = soc_image.select(['soc_0-5cm_mean', 'soc_5-15cm_mean', 'soc_15-30cm_mean'])\n",
    "\n",
    "# Soil Grids 250m v2.0: cfvo_mean (coarse fragments volume)\n",
    "cfvo_image = ee.Image(\"projects/soilgrids-isric/cfvo_mean\")\n",
    "cfvo_image = cfvo_image.select(['cfvo_0-5cm_mean', 'cfvo_5-15cm_mean', 'cfvo_15-30cm_mean'])\n",
    "\n",
    "# Stack the images into a single multiband image\n",
    "soilgrids_image = bdod_image.addBands([clay_image, sand_image, soc_image, cfvo_image])\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Loop over each subset and sample the data\n",
    "for chunk in soildata_chunks:\n",
    "    sampled_points = geemap.extract_values_to_points(chunk, soilgrids_image, scale=250)\n",
    "    sampled_df = geemap.ee_to_df(sampled_points)\n",
    "    dataframes.append(sampled_df)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "soilgrids_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Rename columns\n",
    "# Replace dash with underscores\n",
    "soilgrids_df.columns = soilgrids_df.columns.str.replace('-', '_')\n",
    "# Remove _mean from column names\n",
    "soilgrids_df.columns = soilgrids_df.columns.str.replace('_mean', '')\n",
    "\n",
    "# Print column names\n",
    "print(soilgrids_df.columns)\n",
    "\n",
    "# Check if number of rows of soildata_df is the same as that of soildata_xy\n",
    "# If the number of rows is the same, the merge was successful\n",
    "target = soildata_xy.shape[0]\n",
    "print(\n",
    "  '\\nThere should be', target, 'events:',\n",
    "  target == soilgrids_df.shape[0], '\\nThere are', soilgrids_df.shape[0], 'events')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        bdod_0_5cm  bdod_15_30cm  bdod_5_15cm   cfvo_0_5cm  cfvo_15_30cm  \\\n",
      "count  9215.000000   9215.000000  9215.000000  9234.000000   9234.000000   \n",
      "mean    117.812371    126.489962   121.801845    60.141759     64.182153   \n",
      "std      11.100673     10.490555    10.767095    32.489046     35.335749   \n",
      "min      61.000000     60.000000    60.000000     0.000000      0.000000   \n",
      "25%     111.000000    123.000000   117.000000    35.000000     37.000000   \n",
      "50%     119.000000    129.000000   123.000000    56.000000     59.000000   \n",
      "75%     126.000000    134.000000   129.000000    83.000000     89.000000   \n",
      "max     145.000000    158.000000   148.000000   364.000000    336.000000   \n",
      "\n",
      "       cfvo_5_15cm   clay_0_5cm  clay_15_30cm  clay_5_15cm      coord_x  \\\n",
      "count  9234.000000  9234.000000   9234.000000  9234.000000  9513.000000   \n",
      "mean     61.439138   300.815356    337.883149   303.876976   -53.531505   \n",
      "std      34.679090    98.907864     95.881006   103.371734     8.657161   \n",
      "min       0.000000    56.000000     46.000000    50.000000   -73.783330   \n",
      "25%      34.000000   230.000000    272.000000   233.000000   -61.465833   \n",
      "50%      56.000000   283.000000    324.000000   286.000000   -53.788318   \n",
      "75%      87.000000   356.000000    396.000000   365.750000   -46.633330   \n",
      "max     325.000000   796.000000    820.000000   779.000000   -34.883300   \n",
      "\n",
      "           coord_y  data_coleta_ano   sand_0_5cm  sand_15_30cm  sand_5_15cm  \\\n",
      "count  9513.000000      9513.000000  9234.000000   9234.000000  9234.000000   \n",
      "mean    -15.510067      1985.627667   432.534330    411.360407   436.941520   \n",
      "std       8.940196        17.875184   151.398297    147.665904   157.559211   \n",
      "min     -33.650000      1948.000000    15.000000     14.000000    16.000000   \n",
      "25%     -22.847220      1977.000000   331.000000    307.250000   327.000000   \n",
      "50%     -12.819722      1989.000000   456.000000    426.000000   455.000000   \n",
      "75%      -9.247222      1996.000000   531.000000    503.000000   536.000000   \n",
      "max       4.633333      2018.000000   914.000000    926.000000   928.000000   \n",
      "\n",
      "         soc_0_5cm  soc_15_30cm   soc_5_15cm  \n",
      "count  9215.000000  9215.000000  9215.000000  \n",
      "mean    355.946066   147.189148   206.482908  \n",
      "std     177.937216    84.777842    96.395135  \n",
      "min      50.000000    42.000000    38.000000  \n",
      "25%     232.500000    92.000000   154.000000  \n",
      "50%     289.000000   124.000000   184.000000  \n",
      "75%     449.000000   175.000000   236.500000  \n",
      "max    1259.000000  1031.000000  1596.000000  \n"
     ]
    }
   ],
   "source": [
    "# Compute summary statistics of the SoilGrids data\n",
    "summary = soilgrids_df.describe()\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribution of land cover/land use classes:\n",
      "lulc\n",
      "0                4170\n",
      "forest           1966\n",
      "pasture          1781\n",
      "agriculture       977\n",
      "nonforest         448\n",
      "nonvegetation     112\n",
      "forestry           55\n",
      "unknown             4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "There should be 9513 events: True \n",
      "There are 9513 events\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# MapBiomas LULC Collection 7.1\n",
    "# This takes about xx minutes to run\n",
    "\n",
    "# Import the MapBiomas Collection 7.1\n",
    "collection = 'projects/mapbiomas-workspace/public/collection7_1/mapbiomas_collection71_integration_v1'\n",
    "mapbiomas_image = ee.Image(collection)\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Loop over each subset and sample the data\n",
    "for chunk in soildata_chunks:\n",
    "    sampled_points = geemap.extract_values_to_points(chunk, mapbiomas_image, scale=30)\n",
    "    sampled_df = geemap.ee_to_df(sampled_points)\n",
    "    dataframes.append(sampled_df)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "mapbiomas_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Rename columns\n",
    "# Remove classification_ prefix from column names\n",
    "mapbiomas_df.columns = mapbiomas_df.columns.str.replace('classification_', '')\n",
    "\n",
    "# Get LULC class at the year of sampling (data_coleta_ano)\n",
    "# Each column in the MapBiomas dataset represents a year. The column name is the year of the\n",
    "# classification. The value is the class code. We need to extract the class code for the year of\n",
    "# sampling, which is stored in the data_coleta_ano column.\n",
    "# Step 1: Create a new column YEAR based on data_coleta_ano\n",
    "mapbiomas_df['YEAR'] = mapbiomas_df['data_coleta_ano']\n",
    "# Step 2: If YEAR is less than 1985, set it to 0 (no data)\n",
    "mapbiomas_df.loc[mapbiomas_df['YEAR'] < 1985, 'YEAR'] = 0\n",
    "# Step 3: Find the column index for each YEAR\n",
    "lulc_idx = mapbiomas_df.columns.get_indexer(mapbiomas_df['YEAR'].astype(str))\n",
    "# Step 4: Extract the class code for each row based on the data_coleta_ano column\n",
    "lulc = mapbiomas_df.to_numpy()\n",
    "lulc = lulc[range(len(lulc)), lulc_idx]\n",
    "# Step 5: Convert the extracted class codes to strings and assign them to a new column lulc\n",
    "mapbiomas_df['lulc'] = lulc.astype(str)\n",
    "# Step 6: Drop the YEAR column\n",
    "mapbiomas_df = mapbiomas_df.drop(columns = ['YEAR'])\n",
    "\n",
    "# Some columns of mapbiomas_df are named with the year of the classification, ranging from 1985 to\n",
    "# the present year. This columns need to be dropped.\n",
    "# Drop columns with years as column names\n",
    "current_year = datetime.now().year\n",
    "years_to_drop = [str(year) for year in range(1985, current_year + 1)]\n",
    "mapbiomas_df.drop(columns=years_to_drop, inplace=True, errors='ignore')\n",
    "\n",
    "# Reclassify the land cover classes\n",
    "forest_codes = ['1.0', '3.0', '4.0', '5.0', '49.0']\n",
    "nonforest_codes = ['10.0', '11.0', '12.0', '32.0', '29.0', '50.0', '13.0']\n",
    "pasture_codes = ['15.0']\n",
    "agriculture_codes = ['14.0', '18.0', '19.0', '39.0', '20.0', '40.0', '62.0', '41.0', '36.0', '46.0',\n",
    "                     '47.0', '48.0', '21.0']\n",
    "forestry_codes = ['9.0']\n",
    "nonvegetation_codes = ['22.0', '23.0', '24.0', '30.0', '25.0', '26.0', '33.0', '31.0', '27.0']\n",
    "unknown_codes = ['0', '0.0', 'nan']\n",
    "mapbiomas_df['lulc'] = mapbiomas_df['lulc'].replace(forest_codes, 'forest')\n",
    "mapbiomas_df['lulc'] = mapbiomas_df['lulc'].replace(nonforest_codes, 'nonforest')\n",
    "mapbiomas_df['lulc'] = mapbiomas_df['lulc'].replace(pasture_codes, 'pasture')\n",
    "mapbiomas_df['lulc'] = mapbiomas_df['lulc'].replace(agriculture_codes, 'agriculture')\n",
    "mapbiomas_df['lulc'] = mapbiomas_df['lulc'].replace(forestry_codes, 'forestry')\n",
    "mapbiomas_df['lulc'] = mapbiomas_df['lulc'].replace(nonvegetation_codes, 'nonvegetation')\n",
    "mapbiomas_df['lulc'] = mapbiomas_df['lulc'].replace(unknown_codes, 'unknown')\n",
    "\n",
    "# Print summary of the land cover classes\n",
    "print('\\nDistribution of land cover/land use classes:')\n",
    "print(mapbiomas_df['lulc'].value_counts())\n",
    "\n",
    "# Check if number of rows of mapbiomas_df is the same as that of soildata_xy\n",
    "# If the number of rows is the same, the sampling was successful\n",
    "target = soildata_xy.shape[0]\n",
    "print(\n",
    "  '\\nThere should be', target, 'events:',\n",
    "  target == mapbiomas_df.shape[0], '\\nThere are', mapbiomas_df.shape[0], 'events')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "There should be 21890 events: True \n",
      "There are 21890 events\n"
     ]
    }
   ],
   "source": [
    "# Merge data sampled from SoilGrids and MapBiomas into soildata_df\n",
    "# Keep all rows from soildata_df\n",
    "merge_columns = ['dataset_id', 'observacao_id', 'coord_x', 'coord_y', 'data_coleta_ano']\n",
    "output_df = soildata_df.merge(soilgrids_df, on = merge_columns, how = 'left')\n",
    "output_df = output_df.merge(mapbiomas_df, on = merge_columns, how = 'left')\n",
    "\n",
    "# Fill empty cells in the 'lulc' column with 'unknown'\n",
    "output_df['lulc'] = output_df['lulc'].fillna('unknown')\n",
    "\n",
    "# Check if number of rows of output_df is the same as that of soildata_df\n",
    "# If the number of rows is the same, the merge was successful\n",
    "target = soildata_df.shape[0]\n",
    "print(\n",
    "  '\\nThere should be', target, 'layers:',\n",
    "  target == output_df.shape[0], '\\nThere are', output_df.shape[0], 'layers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Write the output_df to a TXT file\n",
    "# Field separator: tab. Decimal separator: comma\n",
    "file_path = os.path.join(work_dir, 'data', '21_soildata_soc.txt')\n",
    "output_df.to_csv(file_path, sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geemap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
