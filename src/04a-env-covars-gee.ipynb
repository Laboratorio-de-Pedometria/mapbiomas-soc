{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import ee\n",
    "import geemap\n",
    "\n",
    "# Initialize the Earth Engine API\n",
    "ee.Initialize()\n",
    "\n",
    "# Convert DataFrame to Earth Engine Feature Collection\n",
    "soildata_fc = geemap.df_to_ee(soildata_xy, latitude = 'coord_y', longitude = 'coord_x')\n",
    "# soildata_fc = geemap.df_to_ee(soildata_xy.sample(n=2000), latitude = 'coord_y', longitude = 'coord_x')\n",
    "\n",
    "# Function to split a feature collection (sampling points) into chunks\n",
    "def split_sampling_points(fc, chunk_size):\n",
    "    features = fc.toList(fc.size())\n",
    "    chunks = [features.slice(i, i + chunk_size) for i in range(0, features.size().getInfo(), chunk_size)]\n",
    "    return [ee.FeatureCollection(chunk) for chunk in chunks]\n",
    "\n",
    "# Split the sample points into subsets of 1000 points each\n",
    "# This is necessary to avoid timeout errors\n",
    "chunk_size = 1000\n",
    "soildata_chunks = split_sampling_points(soildata_fc, chunk_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['bdod_0_5cm', 'bdod_15_30cm', 'bdod_5_15cm', 'cfvo_0_5cm',\n",
      "       'cfvo_15_30cm', 'cfvo_5_15cm', 'clay_0_5cm', 'clay_15_30cm',\n",
      "       'clay_5_15cm', 'coord_x', 'coord_y', 'data_coleta_ano', 'dataset_id',\n",
      "       'observacao_id', 'sand_0_5cm', 'sand_15_30cm', 'sand_5_15cm',\n",
      "       'soc_0_5cm', 'soc_15_30cm', 'soc_5_15cm'],\n",
      "      dtype='object')\n",
      "\n",
      "There should be 11312 events: True \n",
      "There are 11312 events\n"
     ]
    }
   ],
   "source": [
    "# Soil Grids 250m v2.0\n",
    "# (this takes about 10 minutes to run)\n",
    "\n",
    "# Soil Grids 250m v2.0: bdod_mean (bulk density)\n",
    "bdod_image = ee.Image(\"projects/soilgrids-isric/bdod_mean\")\n",
    "bdod_image = bdod_image.select(['bdod_0-5cm_mean', 'bdod_5-15cm_mean', 'bdod_15-30cm_mean'])\n",
    "\n",
    "# Soil Grids 250m v2.0: clay_mean (clay content)\n",
    "clay_image = ee.Image(\"projects/soilgrids-isric/clay_mean\")\n",
    "clay_image = clay_image.select(['clay_0-5cm_mean', 'clay_5-15cm_mean', 'clay_15-30cm_mean'])\n",
    "\n",
    "# Soil Grids 250m v2.0: sand_mean (sand content)\n",
    "sand_image = ee.Image(\"projects/soilgrids-isric/sand_mean\")\n",
    "sand_image = sand_image.select(['sand_0-5cm_mean', 'sand_5-15cm_mean', 'sand_15-30cm_mean'])\n",
    "\n",
    "# Soil Grids 250m v2.0: soc_mean (soil organic carbon)\n",
    "soc_image = ee.Image(\"projects/soilgrids-isric/soc_mean\")\n",
    "soc_image = soc_image.select(['soc_0-5cm_mean', 'soc_5-15cm_mean', 'soc_15-30cm_mean'])\n",
    "\n",
    "# Soil Grids 250m v2.0: cfvo_mean (coarse fragments volume)\n",
    "cfvo_image = ee.Image(\"projects/soilgrids-isric/cfvo_mean\")\n",
    "cfvo_image = cfvo_image.select(['cfvo_0-5cm_mean', 'cfvo_5-15cm_mean', 'cfvo_15-30cm_mean'])\n",
    "\n",
    "# Stack the images into a single multiband image\n",
    "soilgrids_image = bdod_image.addBands([clay_image, sand_image, soc_image, cfvo_image])\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Loop over each subset and sample the data\n",
    "for chunk in soildata_chunks:\n",
    "    sampled_points = geemap.extract_values_to_points(chunk, soilgrids_image, scale=250)\n",
    "    sampled_df = geemap.ee_to_df(sampled_points)\n",
    "    dataframes.append(sampled_df)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "soilgrids_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Rename columns\n",
    "# Replace dash with underscores\n",
    "soilgrids_df.columns = soilgrids_df.columns.str.replace('-', '_')\n",
    "# Remove _mean from column names\n",
    "soilgrids_df.columns = soilgrids_df.columns.str.replace('_mean', '')\n",
    "\n",
    "# Print column names\n",
    "print(soilgrids_df.columns)\n",
    "\n",
    "# Check if number of rows of soildata_df is the same as that of soildata_xy\n",
    "# If the number of rows is the same, the merge was successful\n",
    "target = soildata_xy.shape[0]\n",
    "print(\n",
    "  '\\nThere should be', target, 'events:',\n",
    "  target == soilgrids_df.shape[0], '\\nThere are', soilgrids_df.shape[0], 'events')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         bdod_0_5cm  bdod_15_30cm   bdod_5_15cm    cfvo_0_5cm  cfvo_15_30cm  \\\n",
      "count  11004.000000  11004.000000  11004.000000  11022.000000  11022.000000   \n",
      "mean     118.057343    126.689295    122.025718     62.028216     66.258302   \n",
      "std       11.322577     10.698621     11.068186     33.820556     37.230729   \n",
      "min       61.000000     60.000000     60.000000      0.000000      0.000000   \n",
      "25%      111.000000    123.000000    117.000000     36.000000     38.000000   \n",
      "50%      119.000000    129.000000    123.000000     56.000000     59.000000   \n",
      "75%      127.000000    134.000000    130.000000     86.000000     92.000000   \n",
      "max      145.000000    158.000000    148.000000    364.000000    336.000000   \n",
      "\n",
      "        cfvo_5_15cm    clay_0_5cm  clay_15_30cm   clay_5_15cm       coord_x  \\\n",
      "count  11022.000000  11022.000000  11022.000000  11022.000000  11312.000000   \n",
      "mean      63.520504    300.562239    339.032662    303.490383    -53.102308   \n",
      "std       36.341861    100.885785     96.424365    104.730938      8.837263   \n",
      "min        0.000000     56.000000     46.000000     50.000000    -73.783330   \n",
      "25%       35.000000    229.000000    273.000000    233.000000    -61.477153   \n",
      "50%       56.000000    281.000000    323.000000    284.000000    -53.500000   \n",
      "75%       90.000000    355.000000    397.000000    363.000000    -46.250226   \n",
      "max      325.000000    796.000000    820.000000    779.000000    -34.883300   \n",
      "\n",
      "            coord_y  data_coleta_ano    sand_0_5cm  sand_15_30cm  \\\n",
      "count  11312.000000     11312.000000  11022.000000  11022.000000   \n",
      "mean     -15.594820      1989.851485    436.233079    413.128561   \n",
      "std        9.072244        18.562962    150.114700    145.075249   \n",
      "min      -33.650000      1948.000000     15.000000     14.000000   \n",
      "25%      -23.040224      1978.000000    340.000000    318.000000   \n",
      "50%      -12.697917      1997.000000    463.000000    431.000000   \n",
      "75%       -9.084783      2000.000000    534.000000    504.000000   \n",
      "max        4.633333      2018.000000    914.000000    926.000000   \n",
      "\n",
      "        sand_5_15cm     soc_0_5cm   soc_15_30cm    soc_5_15cm  \n",
      "count  11022.000000  11004.000000  11004.000000  11004.000000  \n",
      "mean     439.843767    354.692839    144.741549    204.421937  \n",
      "std      155.392647    177.662618     82.712675     96.127269  \n",
      "min       16.000000     50.000000     42.000000     38.000000  \n",
      "25%      338.000000    232.000000     91.000000    152.000000  \n",
      "50%      462.000000    290.000000    123.000000    183.000000  \n",
      "75%      539.000000    457.000000    172.000000    235.000000  \n",
      "max      928.000000   1259.000000   1031.000000   1596.000000  \n"
     ]
    }
   ],
   "source": [
    "# Compute summary statistics of the SoilGrids data\n",
    "summary = soilgrids_df.describe()\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribution of land cover/land use classes:\n",
      "lulc\n",
      "0                4159\n",
      "forest           2757\n",
      "pasture          2186\n",
      "agriculture      1471\n",
      "nonforest         503\n",
      "nonvegetation     143\n",
      "forestry           87\n",
      "unknown             6\n",
      "Name: count, dtype: int64\n",
      "\n",
      "There should be 11312 events: True \n",
      "There are 11312 events\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# MapBiomas LULC Collection 7.1\n",
    "# This takes about xx minutes to run\n",
    "\n",
    "# Import the MapBiomas Collection 7.1\n",
    "collection = 'projects/mapbiomas-workspace/public/collection7_1/mapbiomas_collection71_integration_v1'\n",
    "mapbiomas_image = ee.Image(collection)\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Loop over each subset and sample the data\n",
    "for chunk in soildata_chunks:\n",
    "    sampled_points = geemap.extract_values_to_points(chunk, mapbiomas_image, scale=30)\n",
    "    sampled_df = geemap.ee_to_df(sampled_points)\n",
    "    dataframes.append(sampled_df)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "mapbiomas_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Rename columns\n",
    "# Remove classification_ prefix from column names\n",
    "mapbiomas_df.columns = mapbiomas_df.columns.str.replace('classification_', '')\n",
    "\n",
    "# Get LULC class at the year of sampling (data_coleta_ano)\n",
    "# Each column in the MapBiomas dataset represents a year. The column name is the year of the\n",
    "# classification. The value is the class code. We need to extract the class code for the year of\n",
    "# sampling, which is stored in the data_coleta_ano column.\n",
    "# Step 1: Create a new column YEAR based on data_coleta_ano\n",
    "mapbiomas_df['YEAR'] = mapbiomas_df['data_coleta_ano']\n",
    "# Step 2: If YEAR is less than 1985, set it to 0 (no data)\n",
    "mapbiomas_df.loc[mapbiomas_df['YEAR'] < 1985, 'YEAR'] = 0\n",
    "# Step 3: Find the column index for each YEAR\n",
    "lulc_idx = mapbiomas_df.columns.get_indexer(mapbiomas_df['YEAR'].astype(str))\n",
    "# Step 4: Extract the class code for each row based on the data_coleta_ano column\n",
    "lulc = mapbiomas_df.to_numpy()\n",
    "lulc = lulc[range(len(lulc)), lulc_idx]\n",
    "# Step 5: Convert the extracted class codes to strings and assign them to a new column lulc\n",
    "mapbiomas_df['lulc'] = lulc.astype(str)\n",
    "# Step 6: Drop the YEAR column\n",
    "mapbiomas_df = mapbiomas_df.drop(columns = ['YEAR'])\n",
    "\n",
    "# Some columns of mapbiomas_df are named with the year of the classification, ranging from 1985 to\n",
    "# the present year. This columns need to be dropped.\n",
    "# Drop columns with years as column names\n",
    "current_year = datetime.now().year\n",
    "years_to_drop = [str(year) for year in range(1985, current_year + 1)]\n",
    "mapbiomas_df.drop(columns=years_to_drop, inplace=True, errors='ignore')\n",
    "\n",
    "# Reclassify the land cover classes\n",
    "forest_codes = ['1.0', '3.0', '4.0', '5.0', '49.0']\n",
    "nonforest_codes = ['10.0', '11.0', '12.0', '32.0', '29.0', '50.0', '13.0']\n",
    "pasture_codes = ['15.0']\n",
    "agriculture_codes = ['14.0', '18.0', '19.0', '39.0', '20.0', '40.0', '62.0', '41.0', '36.0', '46.0',\n",
    "                     '47.0', '48.0', '21.0']\n",
    "forestry_codes = ['9.0']\n",
    "nonvegetation_codes = ['22.0', '23.0', '24.0', '30.0', '25.0', '26.0', '33.0', '31.0', '27.0']\n",
    "unknown_codes = ['0.0', 'nan']\n",
    "mapbiomas_df['lulc'] = mapbiomas_df['lulc'].replace(forest_codes, 'forest')\n",
    "mapbiomas_df['lulc'] = mapbiomas_df['lulc'].replace(nonforest_codes, 'nonforest')\n",
    "mapbiomas_df['lulc'] = mapbiomas_df['lulc'].replace(pasture_codes, 'pasture')\n",
    "mapbiomas_df['lulc'] = mapbiomas_df['lulc'].replace(agriculture_codes, 'agriculture')\n",
    "mapbiomas_df['lulc'] = mapbiomas_df['lulc'].replace(forestry_codes, 'forestry')\n",
    "mapbiomas_df['lulc'] = mapbiomas_df['lulc'].replace(nonvegetation_codes, 'nonvegetation')\n",
    "mapbiomas_df['lulc'] = mapbiomas_df['lulc'].replace(unknown_codes, 'unknown')\n",
    "\n",
    "# Print summary of the land cover classes\n",
    "print('\\nDistribution of land cover/land use classes:')\n",
    "print(mapbiomas_df['lulc'].value_counts())\n",
    "\n",
    "# Check if number of rows of mapbiomas_df is the same as that of soildata_xy\n",
    "# If the number of rows is the same, the sampling was successful\n",
    "target = soildata_xy.shape[0]\n",
    "print(\n",
    "  '\\nThere should be', target, 'events:',\n",
    "  target == mapbiomas_df.shape[0], '\\nThere are', mapbiomas_df.shape[0], 'events')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "There should be 17606 events: True \n",
      "There are 17606 events\n"
     ]
    }
   ],
   "source": [
    "# Merge data sampled from SoilGrids and MapBiomas into soildata_df\n",
    "# Keep all rows from soildata_df\n",
    "merge_columns = ['dataset_id', 'observacao_id', 'coord_x', 'coord_y', 'data_coleta_ano']\n",
    "output_df = soildata_df.merge(soilgrids_df, on = merge_columns, how = 'left')\n",
    "output_df = output_df.merge(mapbiomas_df, on = merge_columns, how = 'left')\n",
    "\n",
    "# Check if number of rows of output_df is the same as that of soildata_df\n",
    "# If the number of rows is the same, the merge was successful\n",
    "target = soildata_df.shape[0]\n",
    "print(\n",
    "  '\\nThere should be', target, 'events:',\n",
    "  target == output_df.shape[0], '\\nThere are', output_df.shape[0], 'events')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Write the output_df to a TXT file\n",
    "# Field separator: tab. Decimal separator: comma\n",
    "file_path = os.path.join(work_dir, 'data', '04a-febr-data.txt')\n",
    "output_df.to_csv(file_path, sep='\\t', decimal=',', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geemap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
