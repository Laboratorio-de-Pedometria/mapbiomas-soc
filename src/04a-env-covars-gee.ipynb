{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17606, 61)\n",
      "(17606, 112)\n",
      "The DataFrames are different.\n"
     ]
    }
   ],
   "source": [
    "# MapBiomas Soil (beta): Script 04a. Environmental covariates - get GEE data\n",
    "# Alessandro Samuel-Rosa & Taciara Zborowski Horst\n",
    "# 2024 CC-BY\n",
    "\n",
    "# Import necessary libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Identify working directory, saving the path to a variable\n",
    "src_dir = os.getcwd()\n",
    "work_dir = os.path.dirname(src_dir)\n",
    "\n",
    "# Read the TXT file '03-febr-data.txt' with the soil data from the 'data' folder\n",
    "# Field separator: tab. Decimal separator: comma\n",
    "file_path = os.path.join(work_dir, 'data', '03-febr-data.txt')\n",
    "soildata_df = pd.read_csv(file_path, sep='\\t', decimal=',', low_memory=False)\n",
    "print(soildata_df.shape)\n",
    "\n",
    "# Read the TXT file '04a-febr-data.txt' with the coordinates from the 'data' folder\n",
    "# Field separator: tab. Decimal separator: comma\n",
    "file_path = os.path.join(work_dir, 'data', '04a-febr-data.txt')\n",
    "df2 = pd.read_csv(file_path, sep='\\t', decimal=',', low_memory=False)\n",
    "print(df2.shape)\n",
    "\n",
    "# Compare the two data frames to check if there were changes in the data\n",
    "# Use equals() method to compare the two data frames\n",
    "# The result is a boolean value, True if the data frames are equal, False otherwise\n",
    "# We consider only the following variables in the comparison:\n",
    "# dataset_id, observacao_id, coord_x, coord_y, data_coleta_ano\n",
    "df1 = soildata_df[['dataset_id', 'observacao_id', 'coord_x', 'coord_y', 'data_coleta_ano']]\n",
    "df2 = df2[['dataset_id', 'observacao_id', 'coord_x', 'coord_y', 'data_coleta_ano']]\n",
    "if df1.equals(df2):\n",
    "    print(\"The DataFrames are identical.\")\n",
    "else:\n",
    "    print(\"The DataFrames are different.\")\n",
    "del df1, df2\n",
    "# 17 606 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There should be 11312 events: True \n",
      "There are 11312 events\n"
     ]
    }
   ],
   "source": [
    "# Filter out soil layers without geographic coordinates\n",
    "# coord_x and coord_y are the columns with the geographic coordinates\n",
    "soildata_xy = soildata_df[soildata_df['coord_x'].notnull()]\n",
    "soildata_xy = soildata_xy[soildata_xy['coord_y'].notnull()]\n",
    "\n",
    "# Remove all duplicates based on the following columns:\n",
    "# \"dataset_id\", \"observacao_id\", \"coord_x\", \"coord_y\", \"data_coleta_ano\"\n",
    "# The first occurrence is kept, and the others are removed\n",
    "soildata_xy = soildata_xy[['dataset_id', 'observacao_id', 'coord_x', 'coord_y', 'data_coleta_ano']]\n",
    "soildata_xy = soildata_xy.drop_duplicates()\n",
    "target = 11312\n",
    "print(\n",
    "  'There should be', target, 'events:', target == soildata_xy.shape[0],\n",
    "  '\\nThere are', soildata_xy.shape[0], 'events')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import ee\n",
    "import geemap\n",
    "\n",
    "# Initialize the Earth Engine API\n",
    "ee.Initialize()\n",
    "\n",
    "# Convert DataFrame to Earth Engine Feature Collection\n",
    "soildata_fc = geemap.df_to_ee(soildata_xy, latitude = 'coord_y', longitude = 'coord_x')\n",
    "# soildata_fc = geemap.df_to_ee(soildata_xy.sample(n=100), latitude = 'coord_y', longitude = 'coord_x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There should be 11312 events: True \n",
      "There are 11312 events\n"
     ]
    }
   ],
   "source": [
    "# Soil Grids 250m v2.0\n",
    "# This takes about 30 minutes to run\n",
    "\n",
    "# Soil Grids 250m v2.0: bdod_mean (bulk density)\n",
    "image = ee.Image(\"projects/soilgrids-isric/bdod_mean\")\n",
    "bdod_mean = geemap.extract_values_to_points(soildata_fc, image, scale = 250)\n",
    "bdod_mean = geemap.ee_to_df(bdod_mean)\n",
    "\n",
    "# Soil Grids 250m v2.0: clay_mean (clay content)\n",
    "image = ee.Image(\"projects/soilgrids-isric/clay_mean\")\n",
    "clay_mean = geemap.extract_values_to_points(soildata_fc, image, scale = 250)\n",
    "clay_mean = geemap.ee_to_df(clay_mean)\n",
    "\n",
    "# Soil Grids 250m v2.0: sand_mean (sand content)\n",
    "image = ee.Image(\"projects/soilgrids-isric/sand_mean\")\n",
    "sand_mean = geemap.extract_values_to_points(soildata_fc, image, scale = 250)\n",
    "sand_mean = geemap.ee_to_df(sand_mean)\n",
    "\n",
    "# Soil Grids 250m v2.0: soc_mean (soil organic carbon)\n",
    "image = ee.Image(\"projects/soilgrids-isric/soc_mean\")\n",
    "soc_mean = geemap.extract_values_to_points(soildata_fc, image, scale = 250)\n",
    "soc_mean = geemap.ee_to_df(soc_mean)\n",
    "\n",
    "# Soil Grids 250m v2.0: cfvo_mean (coarse fragments volume)\n",
    "image = ee.Image(\"projects/soilgrids-isric/cfvo_mean\")\n",
    "cfvo_mean = geemap.extract_values_to_points(soildata_fc, image, scale = 250)\n",
    "cfvo_mean = geemap.ee_to_df(cfvo_mean)\n",
    "\n",
    "# Merge dataframes into soilgrids_df\n",
    "merge_columns = ['dataset_id', 'observacao_id', 'coord_x', 'coord_y', 'data_coleta_ano']\n",
    "soilgrids_df = bdod_mean.merge(clay_mean, on = merge_columns)\n",
    "soilgrids_df = soilgrids_df.merge(sand_mean, on = merge_columns)\n",
    "soilgrids_df = soilgrids_df.merge(soc_mean, on = merge_columns)\n",
    "soilgrids_df = soilgrids_df.merge(cfvo_mean, on = merge_columns)\n",
    "\n",
    "# Rename columns\n",
    "# Replace dash with underscores\n",
    "soilgrids_df.columns = soilgrids_df.columns.str.replace('-', '_')\n",
    "# Remove _mean from column names\n",
    "soilgrids_df.columns = soilgrids_df.columns.str.replace('_mean', '')\n",
    "\n",
    "# Drop columns with 30_60cm, 60_100cm or 100_200cm in the name\n",
    "soilgrids_df = soilgrids_df[soilgrids_df.columns.drop(list(soilgrids_df.filter(regex='30_60cm')))]\n",
    "soilgrids_df = soilgrids_df[soilgrids_df.columns.drop(list(soilgrids_df.filter(regex='60_100cm')))]\n",
    "soilgrids_df = soilgrids_df[soilgrids_df.columns.drop(list(soilgrids_df.filter(regex='100_200cm')))]\n",
    "\n",
    "# Check if number of rows of soildata_df is the same as that of soildata_xy\n",
    "# If the number of rows is the same, the merge was successful\n",
    "target = soildata_xy.shape[0]\n",
    "print(\n",
    "  'There should be', target, 'events:',\n",
    "  target == soilgrids_df.shape[0], '\\nThere are', soilgrids_df.shape[0], 'events')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "Exception",
     "evalue": "Computation timed out.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHttpError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/.virtualenvs/geemap/lib/python3.10/site-packages/ee/data.py:402\u001b[0m, in \u001b[0;36m_execute_cloud_call\u001b[0;34m(call, num_retries)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 402\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_retries\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m googleapiclient\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mHttpError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.virtualenvs/geemap/lib/python3.10/site-packages/googleapiclient/_helpers.py:130\u001b[0m, in \u001b[0;36mpositional.<locals>.positional_decorator.<locals>.positional_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(message)\n\u001b[0;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/geemap/lib/python3.10/site-packages/googleapiclient/http.py:938\u001b[0m, in \u001b[0;36mHttpRequest.execute\u001b[0;34m(self, http, num_retries)\u001b[0m\n\u001b[1;32m    937\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[0;32m--> 938\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HttpError(resp, content, uri\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muri)\n\u001b[1;32m    939\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostproc(resp, content)\n",
      "\u001b[0;31mHttpError\u001b[0m: <HttpError 400 when requesting https://earthengine.googleapis.com/v1/projects/earthengine-legacy/value:compute?prettyPrint=false&alt=json returned \"Computation timed out.\". Details: \"Computation timed out.\">",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mEEException\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/.virtualenvs/geemap/lib/python3.10/site-packages/geemap/common.py:9110\u001b[0m, in \u001b[0;36mee_to_df\u001b[0;34m(ee_object, columns, remove_geom, sort_columns, **kwargs)\u001b[0m\n\u001b[1;32m   9109\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 9110\u001b[0m     property_names \u001b[38;5;241m=\u001b[39m \u001b[43mee_object\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfirst\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpropertyNames\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetInfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   9111\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m remove_geom:\n",
      "File \u001b[0;32m~/.virtualenvs/geemap/lib/python3.10/site-packages/ee/computedobject.py:107\u001b[0m, in \u001b[0;36mComputedObject.getInfo\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fetch and return information about this object.\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \n\u001b[1;32m    104\u001b[0m \u001b[38;5;124;03mReturns:\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;124;03m  The object can evaluate to anything.\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomputeValue\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/geemap/lib/python3.10/site-packages/ee/data.py:1108\u001b[0m, in \u001b[0;36mcomputeValue\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m   1106\u001b[0m _maybe_populate_workload_tag(body)\n\u001b[0;32m-> 1108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_execute_cloud_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_get_cloud_projects\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1110\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_get_projects_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprettyPrint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1112\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/.virtualenvs/geemap/lib/python3.10/site-packages/ee/data.py:404\u001b[0m, in \u001b[0;36m_execute_cloud_call\u001b[0;34m(call, num_retries)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m googleapiclient\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mHttpError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 404\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m _translate_cloud_exception(e)\n",
      "\u001b[0;31mEEException\u001b[0m: Computation timed out.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1059677/3783360703.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mee\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcollection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Extract the land cover information from the MapBiomas Collection 7.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmapbiomas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgeemap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_values_to_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoildata_fc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmapbiomas_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgeemap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mee_to_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapbiomas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Rename columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Remove classification_ prefix from column names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/geemap/lib/python3.10/site-packages/geemap/common.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(ee_object, columns, remove_geom, sort_columns, **kwargs)\u001b[0m\n\u001b[1;32m   9130\u001b[0m             \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9132\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9133\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 9134\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mException\u001b[0m: Computation timed out."
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# MapBiomas LULC Collection 7.1\n",
    "# This takes about xx minutes to run\n",
    "\n",
    "# Import the MapBiomas Collection 7.1\n",
    "collection = 'projects/mapbiomas-workspace/public/collection7_1/mapbiomas_collection71_integration_v1'\n",
    "image = ee.Image(collection)\n",
    "\n",
    "# Extract the land cover information from the MapBiomas Collection 7.1\n",
    "mapbiomas = geemap.extract_values_to_points(soildata_fc, image, scale = 30)\n",
    "mapbiomas_df = geemap.ee_to_df(mapbiomas)\n",
    "\n",
    "# Rename columns\n",
    "# Remove classification_ prefix from column names\n",
    "mapbiomas_df.columns = mapbiomas_df.columns.str.replace('classification_', '')\n",
    "\n",
    "# Get LULC class at the year of sampling (data_coleta_ano)\n",
    "# Each column in the MapBiomas dataset represents a year. The column name is the year of the\n",
    "# classification. The value is the class code. We need to extract the class code for the year of\n",
    "# sampling, which is stored in the data_coleta_ano column.\n",
    "# Step 1: Create a new column YEAR based on data_coleta_ano\n",
    "mapbiomas_df['YEAR'] = mapbiomas_df['data_coleta_ano']\n",
    "# Step 2: If YEAR is less than 1985, set it to 0 (no data)\n",
    "mapbiomas_df.loc[mapbiomas_df['YEAR'] < 1985, 'YEAR'] = 0\n",
    "# Step 3: Find the column index for each YEAR\n",
    "lulc_idx = mapbiomas_df.columns.get_indexer(mapbiomas_df['YEAR'].astype(str))\n",
    "# Step 4: Extract the class code for each row based on the data_coleta_ano column\n",
    "lulc = mapbiomas_df.to_numpy()\n",
    "lulc = lulc[range(len(lulc)), lulc_idx]\n",
    "# Step 5: Convert the extracted class codes to strings and assign them to a new column lulc\n",
    "mapbiomas_df['lulc'] = lulc.astype(str)\n",
    "# Step 6: Drop the YEAR column\n",
    "mapbiomas_df = mapbiomas_df.drop(columns = ['YEAR'])\n",
    "\n",
    "# Some columns of mapbiomas_df are named with the year of the classification, ranging from 1985 to\n",
    "# the present year. This columns need to be dropped.\n",
    "# Drop columns with years as column names\n",
    "current_year = datetime.now().year\n",
    "years_to_drop = [str(year) for year in range(1985, current_year + 1)]\n",
    "mapbiomas_df.drop(columns=years_to_drop, inplace=True, errors='ignore')\n",
    "\n",
    "# Reclassify the land cover classes\n",
    "forest_codes = ['1', '3', '4', '5', '49']\n",
    "nonforest_codes = ['10', '11', '12', '32', '29', '50', '13']\n",
    "pasture_codes = ['15']\n",
    "agriculture_codes = ['14', '18', '19', '39', '20', '40', '62', '41', '36', '46', '47', '48', '21']\n",
    "forestry_codes = ['9']\n",
    "nonvegetation_codes = ['22', '23', '24', '30', '25', '26', '33', '31', '27']\n",
    "unknown_codes = ['0']\n",
    "mapbiomas_df['lulc'] = mapbiomas_df['lulc'].replace(forest_codes, 'forest')\n",
    "mapbiomas_df['lulc'] = mapbiomas_df['lulc'].replace(nonforest_codes, 'nonforest')\n",
    "mapbiomas_df['lulc'] = mapbiomas_df['lulc'].replace(pasture_codes, 'pasture')\n",
    "mapbiomas_df['lulc'] = mapbiomas_df['lulc'].replace(agriculture_codes, 'agriculture')\n",
    "mapbiomas_df['lulc'] = mapbiomas_df['lulc'].replace(forestry_codes, 'forestry')\n",
    "mapbiomas_df['lulc'] = mapbiomas_df['lulc'].replace(nonvegetation_codes, 'nonvegetation')\n",
    "mapbiomas_df['lulc'] = mapbiomas_df['lulc'].replace(unknown_codes, 'unknown')\n",
    "\n",
    "# Print summary of the land cover classes\n",
    "print('\\nDistribution of land cover/land use classes:')\n",
    "print(mapbiomas_df['lulc'].value_counts())\n",
    "\n",
    "# Check if number of rows of mapbiomas_df is the same as that of soildata_xy\n",
    "# If the number of rows is the same, the sampling was successful\n",
    "target = soildata_xy.shape[0]\n",
    "print(\n",
    "  '\\nThere should be', target, 'events:',\n",
    "  target == mapbiomas_df.shape[0], '\\nThere are', mapbiomas_df.shape[0], 'events')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "The number of rows of soilgrids_df, mapbiomas_df, and soildata_xy must be the same.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[82], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Merge data sampled from SoilGrids and MapBiomas into soildata_xy\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m soilgrids_df\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m soildata_xy\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m mapbiomas_df\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m soildata_xy\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe number of rows of soilgrids_df, mapbiomas_df, and soildata_xy must be the same.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Merge dataframes into soildata_xy\u001b[39;00m\n\u001b[1;32m      6\u001b[0m merge_columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobservacao_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoord_x\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoord_y\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_coleta_ano\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: The number of rows of soilgrids_df, mapbiomas_df, and soildata_xy must be the same."
     ]
    }
   ],
   "source": [
    "# Merge data sampled from SoilGrids and MapBiomas into soildata_xy\n",
    "if soilgrids_df.shape[0] != soildata_xy.shape[0] or mapbiomas_df.shape[0] != soildata_xy.shape[0]:\n",
    "    raise ValueError('The number of rows of soilgrids_df, mapbiomas_df, and soildata_xy must be the same.')\n",
    "\n",
    "# Merge dataframes into soildata_xy\n",
    "merge_columns = ['dataset_id', 'observacao_id', 'coord_x', 'coord_y', 'data_coleta_ano']\n",
    "soildata_xy = soildata_xy.merge(soilgrids_df, on = merge_columns)\n",
    "soildata_xy = soildata_xy.merge(mapbiomas_df, on = merge_columns)\n",
    "\n",
    "# Check if number of rows of soildata_xy is the same as that of soilgrids_df and mapbiomas_df\n",
    "# If the number of rows is the same, the merge was successful\n",
    "target = soilgrids_df.shape[0]\n",
    "print(\n",
    "  '\\nThere should be', target, 'events:',\n",
    "  target == soildata_xy.shape[0], '\\nThere are', soildata_xy.shape[0], 'events')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geemap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
