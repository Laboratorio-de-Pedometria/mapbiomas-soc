{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29881, 85)\n",
      "(29683, 122)\n",
      "The DataFrames are different.\n"
     ]
    }
   ],
   "source": [
    "# title: SoilData - Soil Organic Carbon Stock\n",
    "# subtitle: Prepare environmental covariates\n",
    "# author: Alessandro Samuel-Rosa and Taciara Zborowski Horst\n",
    "# data: 2024 CC-BY\n",
    "\n",
    "# Import necessary libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Identify working directory, saving the path to a variable\n",
    "src_dir = os.getcwd()\n",
    "work_dir = os.path.dirname(src_dir)\n",
    "\n",
    "# Read the TXT file '20_soildata_soc.txt' with the soil data from the 'data' folder\n",
    "# Field separator: tab\n",
    "file_path = os.path.join(work_dir, 'data', '20_soildata_soc.txt')\n",
    "soildata_df = pd.read_csv(file_path, sep='\\t', low_memory=False)\n",
    "print(soildata_df.shape)\n",
    "\n",
    "# Read the TXT file '21_soildata_soc.txt' with the coordinates from the 'data' folder\n",
    "# Field separator: tab. Decimal separator: comma\n",
    "file_path = os.path.join(work_dir, 'data', '21_soildata_soc.txt')\n",
    "df2 = pd.read_csv(file_path, sep='\\t', low_memory=False)\n",
    "print(df2.shape)\n",
    "\n",
    "# Compare the two data frames to check if there were changes in the data\n",
    "# Use equals() method to compare the two data frames\n",
    "# The result is a boolean value, True if the data frames are equal, False otherwise\n",
    "# We consider only the following variables in the comparison:\n",
    "# dataset_id, observacao_id, coord_x, coord_y, data_ano\n",
    "df1 = soildata_df[['dataset_id', 'observacao_id', 'coord_x', 'coord_y', 'data_ano']]\n",
    "df2 = df2[['dataset_id', 'observacao_id', 'coord_x', 'coord_y', 'data_ano']]\n",
    "if df1.equals(df2):\n",
    "    print(\"The DataFrames are identical.\")\n",
    "else:\n",
    "    print(\"The DataFrames are different.\")\n",
    "del df1, df2\n",
    "# 29683 layers (GET FROM PREVIOUS SCRIPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There should be 13292 events: False \n",
      "There are 13381 events\n"
     ]
    }
   ],
   "source": [
    "# Filter out soil layers without geographic coordinates\n",
    "# coord_x and coord_y are the columns with the geographic coordinates\n",
    "soildata_xy = soildata_df[soildata_df['coord_x'].notnull()]\n",
    "soildata_xy = soildata_xy[soildata_xy['coord_y'].notnull()]\n",
    "\n",
    "# Remove all duplicates based on the following columns:\n",
    "# \"dataset_id\", \"observacao_id\", \"coord_x\", \"coord_y\", \"data_ano\"\n",
    "# The first occurrence is kept, and the others are removed\n",
    "soildata_xy = soildata_xy[['dataset_id', 'observacao_id', 'coord_x', 'coord_y', 'data_ano']]\n",
    "soildata_xy = soildata_xy.drop_duplicates()\n",
    "target = 13292 # GET VALUE FROM PREVIOUS SCRIPT!\n",
    "print(\n",
    "  'There should be', target, 'events:', target == soildata_xy.shape[0],\n",
    "  '\\nThere are', soildata_xy.shape[0], 'events')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      dataset_id observacao_id    coord_x    coord_y  data_ano\n",
      "0        ctb0003   sm-dnos-001 -53.794645 -29.651271    2009.0\n",
      "1        ctb0003   sm-dnos-002 -53.793987 -29.650564    2009.0\n",
      "2        ctb0003   sm-dnos-003 -53.793993 -29.650232    2009.0\n",
      "3        ctb0003   sm-dnos-004 -53.794345 -29.650311    2009.0\n",
      "4        ctb0003   sm-dnos-005 -53.792947 -29.650838    2009.0\n",
      "...          ...           ...        ...        ...       ...\n",
      "29869    ctb0838            74 -43.997580 -22.564130    2014.0\n",
      "29871    ctb0838            75 -43.994350 -22.522300    2014.0\n",
      "29873    ctb0838            78 -43.989760 -22.530160    2014.0\n",
      "29876    ctb0838            88 -44.007310 -22.531180    2014.0\n",
      "29879    ctb0838            89 -44.006970 -22.530190    2014.0\n",
      "\n",
      "[13381 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Print the first 5 rows of the data frame\n",
    "print(soildata_xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>To authorize access needed by Earth Engine, open the following\n",
       "        URL in a web browser and follow the instructions:</p>\n",
       "        <p><a href=https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/cloud-platform%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=5cNtlMdmFQgVQOQ7Gb1vb9evvsBFiP6YnVsndbf0WgM&tc=uuknyrcsperLdU0R6B9vClOt_eR76nokwkVT_dKlVwY&cc=G7jhVwytu6da1qaCHh1kUH4YcAlkUmlK9eGRNzIMULA>https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/cloud-platform%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=5cNtlMdmFQgVQOQ7Gb1vb9evvsBFiP6YnVsndbf0WgM&tc=uuknyrcsperLdU0R6B9vClOt_eR76nokwkVT_dKlVwY&cc=G7jhVwytu6da1qaCHh1kUH4YcAlkUmlK9eGRNzIMULA</a></p>\n",
       "        <p>The authorization workflow will generate a code, which you should paste in the box below.</p>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully saved authorization token.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "*** Earth Engine *** Share your feedback by taking our Annual Developer Satisfaction Survey: https://google.qualtrics.com/jfe/form/SV_0JLhFqfSY1uiEaW?source=Init\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13381 features\n",
      "14 chunks\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import ee\n",
    "import geemap\n",
    "\n",
    "# GEE user authentication\n",
    "ee.Authenticate()\n",
    "\n",
    "# Initialize the Earth Engine API\n",
    "ee.Initialize()\n",
    "\n",
    "# Convert DataFrame to Earth Engine Feature Collection\n",
    "soildata_fc = geemap.df_to_ee(soildata_xy, latitude = 'coord_y', longitude = 'coord_x')\n",
    "print(soildata_fc.size().getInfo(), 'features')\n",
    "\n",
    "# Function to split a feature collection (sampling points) into chunks\n",
    "def split_sampling_points(fc, chunk_size):\n",
    "    features = fc.toList(fc.size())\n",
    "    chunks = [features.slice(i, i + chunk_size) for i in range(0, features.size().getInfo(), chunk_size)]\n",
    "    return [ee.FeatureCollection(chunk) for chunk in chunks]\n",
    "\n",
    "# Split the sample points into subsets of 1000 points each\n",
    "# This is necessary to avoid timeout errors\n",
    "chunk_size = 1000\n",
    "soildata_chunks = split_sampling_points(soildata_fc, chunk_size)\n",
    "print(len(soildata_chunks), 'chunks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['bdod_0_5cm', 'bdod_15_30cm', 'bdod_5_15cm', 'cfvo_0_5cm',\n",
      "       'cfvo_15_30cm', 'cfvo_5_15cm', 'clay_0_5cm', 'clay_15_30cm',\n",
      "       'clay_5_15cm', 'coord_x', 'coord_y', 'data_ano', 'dataset_id',\n",
      "       'observacao_id', 'sand_0_5cm', 'sand_15_30cm', 'sand_5_15cm',\n",
      "       'soc_0_5cm', 'soc_15_30cm', 'soc_5_15cm'],\n",
      "      dtype='object')\n",
      "\n",
      "There should be 13381 events: True \n",
      "There are 13381 events\n"
     ]
    }
   ],
   "source": [
    "# Soil Grids 250m v2.0\n",
    "# (this takes about 10 minutes to run)\n",
    "\n",
    "# Soil Grids 250m v2.0: bdod_mean (bulk density)\n",
    "bdod_image = ee.Image(\"projects/soilgrids-isric/bdod_mean\")\n",
    "bdod_image = bdod_image.select(['bdod_0-5cm_mean', 'bdod_5-15cm_mean', 'bdod_15-30cm_mean'])\n",
    "\n",
    "# Soil Grids 250m v2.0: clay_mean (clay content)\n",
    "clay_image = ee.Image(\"projects/soilgrids-isric/clay_mean\")\n",
    "clay_image = clay_image.select(['clay_0-5cm_mean', 'clay_5-15cm_mean', 'clay_15-30cm_mean'])\n",
    "\n",
    "# Soil Grids 250m v2.0: sand_mean (sand content)\n",
    "sand_image = ee.Image(\"projects/soilgrids-isric/sand_mean\")\n",
    "sand_image = sand_image.select(['sand_0-5cm_mean', 'sand_5-15cm_mean', 'sand_15-30cm_mean'])\n",
    "\n",
    "# Soil Grids 250m v2.0: soc_mean (soil organic carbon)\n",
    "soc_image = ee.Image(\"projects/soilgrids-isric/soc_mean\")\n",
    "soc_image = soc_image.select(['soc_0-5cm_mean', 'soc_5-15cm_mean', 'soc_15-30cm_mean'])\n",
    "\n",
    "# Soil Grids 250m v2.0: cfvo_mean (coarse fragments volume)\n",
    "cfvo_image = ee.Image(\"projects/soilgrids-isric/cfvo_mean\")\n",
    "cfvo_image = cfvo_image.select(['cfvo_0-5cm_mean', 'cfvo_5-15cm_mean', 'cfvo_15-30cm_mean'])\n",
    "\n",
    "# Stack the images into a single multiband image\n",
    "soilgrids_image = bdod_image.addBands([clay_image, sand_image, soc_image, cfvo_image])\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Loop over each subset and sample the data\n",
    "for chunk in soildata_chunks:\n",
    "    sampled_points = geemap.extract_values_to_points(chunk, soilgrids_image, scale=250)\n",
    "    sampled_df = geemap.ee_to_df(sampled_points)\n",
    "    dataframes.append(sampled_df)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "soilgrids_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Rename columns\n",
    "# Replace dash with underscores\n",
    "soilgrids_df.columns = soilgrids_df.columns.str.replace('-', '_')\n",
    "# Remove _mean from column names\n",
    "soilgrids_df.columns = soilgrids_df.columns.str.replace('_mean', '')\n",
    "\n",
    "# Print column names\n",
    "print(soilgrids_df.columns)\n",
    "\n",
    "# Check if number of rows of soildata_df is the same as that of soildata_xy\n",
    "# If the number of rows is the same, the merge was successful\n",
    "target = soildata_xy.shape[0]\n",
    "print(\n",
    "  '\\nThere should be', target, 'events:',\n",
    "  target == soilgrids_df.shape[0], '\\nThere are', soilgrids_df.shape[0], 'events')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         bdod_0_5cm  bdod_15_30cm   bdod_5_15cm    cfvo_0_5cm  cfvo_15_30cm  \\\n",
      "count  13086.000000  13086.000000  13086.000000  13102.000000  13102.000000   \n",
      "mean     117.701895    126.053187    121.594299     62.542589     66.840788   \n",
      "std       11.336127     10.724247     11.060162     33.305375     36.243606   \n",
      "min       61.000000     60.000000     60.000000      0.000000      0.000000   \n",
      "25%      111.000000    121.000000    116.000000     36.000000     39.000000   \n",
      "50%      118.000000    128.000000    123.000000     58.000000     61.000000   \n",
      "75%      126.000000    134.000000    129.000000     86.000000     93.000000   \n",
      "max      145.000000    158.000000    148.000000    364.000000    336.000000   \n",
      "\n",
      "        cfvo_5_15cm    clay_0_5cm  clay_15_30cm   clay_5_15cm       coord_x  \\\n",
      "count  13102.000000  13102.000000  13102.000000  13102.000000  13381.000000   \n",
      "mean      63.853076    310.440925    345.596626    313.234239    -52.668279   \n",
      "std       35.432377    105.257271    100.442192    107.635174      8.480355   \n",
      "min        0.000000     56.000000     46.000000     50.000000    -73.783330   \n",
      "25%       36.000000    235.000000    275.000000    237.000000    -60.957222   \n",
      "50%       58.000000    289.000000    327.000000    293.000000    -53.581038   \n",
      "75%       90.000000    370.000000    407.000000    377.000000    -45.800000   \n",
      "max      325.000000    796.000000    820.000000    779.000000    -34.883300   \n",
      "\n",
      "            coord_y      data_ano    sand_0_5cm  sand_15_30cm   sand_5_15cm  \\\n",
      "count  13381.000000  13381.000000  13102.000000  13102.000000  13102.000000   \n",
      "mean     -16.487456   1993.555863    424.039689    404.119142    428.265990   \n",
      "std        9.062978     19.598312    149.709325    143.993496    154.294198   \n",
      "min      -33.650000   1948.000000     15.000000     14.000000     16.000000   \n",
      "25%      -25.019827   1980.000000    320.000000    301.000000    320.000000   \n",
      "50%      -14.900000   1996.000000    446.000000    421.000000    448.000000   \n",
      "75%       -9.513611   2010.000000    527.000000    498.750000    531.000000   \n",
      "max        4.633333   2024.000000    914.000000    926.000000    928.000000   \n",
      "\n",
      "          soc_0_5cm   soc_15_30cm    soc_5_15cm  \n",
      "count  13086.000000  13086.000000  13086.000000  \n",
      "mean     366.086887    149.399587    206.686688  \n",
      "std      182.155290     81.097390     95.005725  \n",
      "min       50.000000     42.000000     38.000000  \n",
      "25%      232.000000     93.000000    153.000000  \n",
      "50%      300.000000    130.000000    184.000000  \n",
      "75%      485.000000    181.000000    237.000000  \n",
      "max     1259.000000   1256.000000   1596.000000  \n"
     ]
    }
   ],
   "source": [
    "# Compute summary statistics of the SoilGrids data\n",
    "summary = soilgrids_df.describe()\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# MapBiomas LULC Collection\n",
    "# (this takes about 10 minutes to run)\n",
    "\n",
    "# Import the MapBiomas Collection 9.0\n",
    "collection = 'projects/mapbiomas-public/assets/brazil/lulc/collection9/mapbiomas_collection90_integration_v1'\n",
    "mapbiomas_image = ee.Image(collection)\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Loop over each subset and sample the data\n",
    "for chunk in soildata_chunks:\n",
    "    sampled_points = geemap.extract_values_to_points(chunk, mapbiomas_image, scale=30)\n",
    "    sampled_df = geemap.ee_to_df(sampled_points)\n",
    "    dataframes.append(sampled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribution of land cover/land use classes (including NA):\n",
      "lulc\n",
      "<NA>             4236\n",
      "forest           3354\n",
      "pasture          2667\n",
      "agriculture      1690\n",
      "nonforest        1023\n",
      "nonvegetation     211\n",
      "forestry          189\n",
      "2024               11\n",
      "Name: count, dtype: int64\n",
      "\n",
      "There should be 13381 events: True \n",
      "There are 13381 events\n"
     ]
    }
   ],
   "source": [
    "# Concatenate all DataFrames into a single DataFrame\n",
    "mapbiomas_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Rename columns\n",
    "# Remove classification_ prefix from column names\n",
    "mapbiomas_df.columns = mapbiomas_df.columns.str.replace('classification_', '')\n",
    "\n",
    "# Get LULC class at the year of sampling (data_ano)\n",
    "# Each column in the MapBiomas dataset represents a year. The column name is the year of the\n",
    "# classification. The value is the class code. We need to extract the class code for the year of\n",
    "# sampling, which is stored in the data_ano column.\n",
    "# Step 1: Create a new column YEAR based on data_ano\n",
    "mapbiomas_df['YEAR'] = mapbiomas_df['data_ano']\n",
    "# Step 2: If YEAR is less than 1985, set it to 0 (no data)\n",
    "mapbiomas_df.loc[mapbiomas_df['YEAR'] < 1985, 'YEAR'] = 0\n",
    "# Step 3: Find the column index for each YEAR\n",
    "lulc_idx = mapbiomas_df.columns.get_indexer(mapbiomas_df['YEAR'].astype(str))\n",
    "# Step 4: Extract the class code for each row based on the data_ano column\n",
    "lulc = mapbiomas_df.to_numpy()\n",
    "lulc = lulc[range(len(lulc)), lulc_idx]\n",
    "# Step 5: Convert the extracted class codes to strings and assign them to a new column lulc\n",
    "mapbiomas_df['lulc'] = lulc.astype(str)\n",
    "# Step 6: Drop the YEAR column\n",
    "mapbiomas_df = mapbiomas_df.drop(columns = ['YEAR'])\n",
    "\n",
    "# Some columns of mapbiomas_df are named with the year of the classification, ranging from 1985 to\n",
    "# the present year. This columns need to be dropped.\n",
    "# Drop columns with years as column names\n",
    "current_year = datetime.now().year\n",
    "years_to_drop = [str(year) for year in range(1985, current_year + 1)]\n",
    "mapbiomas_df.drop(columns=years_to_drop, inplace=True, errors='ignore')\n",
    "\n",
    "# Reclassify the land cover classes\n",
    "forest_codes = ['1.0', '3.0', '4.0', '5.0', '6.0', '49.0']\n",
    "nonforest_codes = ['10.0', '11.0', '12.0', '32.0', '29.0', '50.0']\n",
    "pasture_codes = ['15.0']\n",
    "agriculture_codes = [\n",
    "    '14.0', '18.0', '19.0', '39.0', '20.0', '40.0', '62.0', '41.0', '36.0', '46.0', '47.0', '48.0',\n",
    "    '21.0', '35.0']\n",
    "forestry_codes = ['9.0']\n",
    "nonvegetation_codes = ['22.0', '23.0', '24.0', '30.0', '25.0', '26.0', '33.0', '31.0', '27.0']\n",
    "na_codes = ['0', '0.0', 'nan']\n",
    "mapbiomas_df['lulc'] = mapbiomas_df['lulc'].replace(forest_codes, 'forest')\n",
    "mapbiomas_df['lulc'] = mapbiomas_df['lulc'].replace(nonforest_codes, 'nonforest')\n",
    "mapbiomas_df['lulc'] = mapbiomas_df['lulc'].replace(pasture_codes, 'pasture')\n",
    "mapbiomas_df['lulc'] = mapbiomas_df['lulc'].replace(agriculture_codes, 'agriculture')\n",
    "mapbiomas_df['lulc'] = mapbiomas_df['lulc'].replace(forestry_codes, 'forestry')\n",
    "mapbiomas_df['lulc'] = mapbiomas_df['lulc'].replace(nonvegetation_codes, 'nonvegetation')\n",
    "mapbiomas_df['lulc'] = mapbiomas_df['lulc'].replace(na_codes, pd.NA)\n",
    "\n",
    "# Print summary of the land cover classes, including NA\n",
    "print('\\nDistribution of land cover/land use classes (including NA):')\n",
    "print(mapbiomas_df['lulc'].value_counts(dropna=False))\n",
    "\n",
    "# Check if number of rows of mapbiomas_df is the same as that of soildata_xy\n",
    "# If the number of rows is the same, the sampling was successful\n",
    "target = soildata_xy.shape[0]\n",
    "print(\n",
    "  '\\nThere should be', target, 'events:',\n",
    "  target == mapbiomas_df.shape[0], '\\nThere are', mapbiomas_df.shape[0], 'events')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['aspect', 'aspect_cosine', 'aspect_sine', 'convergence', 'coord_x',\n",
      "       'coord_y', 'cti', 'data_ano', 'dataset_id', 'dev_magnitude',\n",
      "       'dev_scale', 'dx', 'dxx', 'dxy', 'dy', 'dyy', 'eastness', 'elev_stdev',\n",
      "       'geom', 'northness', 'observacao_id', 'pcurv', 'rough_magnitude',\n",
      "       'roughness', 'slope', 'spi'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Geomorphometry 90 m\n",
    "\n",
    "# Sample the terrain attributes\n",
    "# projects/mapbiomas-workspace/SOLOS/COVARIAVEIS/OT_GEOMORPHOMETRY_90m\n",
    "# (this takes about 10 minutes to run)\n",
    "dem = ee.Image(\"projects/mapbiomas-workspace/SOLOS/COVARIAVEIS/OT_GEOMORPHOMETRY_90m\")\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "dem_dfs = []\n",
    "\n",
    "# Loop over each subset and sample the data\n",
    "for chunk in soildata_chunks:\n",
    "    sampled_points = geemap.extract_values_to_points(chunk, dem, scale=90)\n",
    "    sampled_df = geemap.ee_to_df(sampled_points)\n",
    "    dem_dfs.append(sampled_df)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "dem_dataframe = pd.concat(dem_dfs, ignore_index=True)\n",
    "\n",
    "# print column names\n",
    "print(dem_dataframe.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             aspect  aspect_cosine   aspect_sine   convergence       coord_x  \\\n",
      "count  13377.000000   13347.000000  13377.000000  13377.000000  13381.000000   \n",
      "mean     182.953342      -0.020292     -0.019612     -2.944035    -52.668279   \n",
      "std      102.680984       0.656210      0.653156     25.632147      8.480355   \n",
      "min        0.074554      -0.999748     -0.999727    -85.449432    -73.783330   \n",
      "25%       95.621498      -0.650972     -0.635149    -19.795198    -60.957222   \n",
      "50%      186.064224      -0.047982     -0.049310     -3.478558    -53.581038   \n",
      "75%      269.087708       0.607631      0.607330     14.010069    -45.800000   \n",
      "max      359.995667       0.999829      0.999761     83.113701    -34.883300   \n",
      "\n",
      "            coord_y           cti      data_ano  dev_magnitude     dev_scale  \\\n",
      "count  13381.000000  13377.000000  13381.000000   13377.000000  13377.000000   \n",
      "mean     -16.487456     -0.269968   1993.555863       0.321840    803.499439   \n",
      "std        9.062978      2.175140     19.598312       1.404813   1304.105165   \n",
      "min      -33.650000     -4.196749   1948.000000      -4.350610      1.000000   \n",
      "25%      -25.019827     -1.634097   1980.000000      -0.945698     16.000000   \n",
      "50%      -14.900000     -0.727515   1996.000000       0.440730    109.000000   \n",
      "75%       -9.513611      0.502823   2010.000000       1.368695    886.000000   \n",
      "max        4.633333     13.967396   2024.000000      14.537906   3997.000000   \n",
      "\n",
      "       ...           dyy      eastness    elev_stdev          geom  \\\n",
      "count  ...  13377.000000  13377.000000  13377.000000  13377.000000   \n",
      "mean   ...      0.000034     -0.001481      6.183497      4.946625   \n",
      "std    ...      0.000552      0.071124      6.919283      2.458992   \n",
      "min    ...     -0.004197     -0.465084      0.003226      1.000000   \n",
      "25%    ...     -0.000123     -0.022712      1.913707      3.000000   \n",
      "50%    ...      0.000014     -0.000771      3.764862      6.000000   \n",
      "75%    ...      0.000170      0.019062      7.423958      6.000000   \n",
      "max    ...      0.008048      0.546383     61.832706     10.000000   \n",
      "\n",
      "          northness         pcurv  rough_magnitude     roughness  \\\n",
      "count  13377.000000  13377.000000     13377.000000  13377.000000   \n",
      "mean      -0.002772     -0.000002         5.618955     19.278375   \n",
      "std        0.070006      0.000531         3.739012     21.521034   \n",
      "min       -0.504372     -0.004733         0.777752      0.009520   \n",
      "25%       -0.024136     -0.000154         2.963066      5.997496   \n",
      "50%       -0.000810      0.000006         4.244001     11.796589   \n",
      "75%        0.018775      0.000160         7.480603     23.089581   \n",
      "max        0.490504      0.006238        23.099562    193.295090   \n",
      "\n",
      "              slope           spi  \n",
      "count  13377.000000  13377.000000  \n",
      "mean       3.921629      1.421483  \n",
      "std        4.502695     24.697127  \n",
      "min        0.002269      0.000084  \n",
      "25%        1.108025      0.000689  \n",
      "50%        2.350850      0.001912  \n",
      "75%        4.771822      0.007237  \n",
      "max       34.743828   1310.350098  \n",
      "\n",
      "[8 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "# Compute summary statistics of the Geomorphometry data\n",
    "summary = dem_dataframe.describe()\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "There should be 29881 layers: True \n",
      "There are 29881 layers\n"
     ]
    }
   ],
   "source": [
    "# Merge data sampled from SoilGrids, MapBiomas, and Geomorphometry into soildata_df\n",
    "# Keep all rows from soildata_df\n",
    "merge_columns = ['dataset_id', 'observacao_id', 'coord_x', 'coord_y', 'data_ano']\n",
    "output_df = soildata_df.merge(soilgrids_df, on = merge_columns, how = 'left')\n",
    "output_df = output_df.merge(mapbiomas_df, on = merge_columns, how = 'left')\n",
    "output_df = output_df.merge(dem_dataframe, on = merge_columns, how = 'left')\n",
    "\n",
    "# # Fill empty cells in the 'lulc' column with 'unknown'\n",
    "# output_df['lulc'] = output_df['lulc'].fillna('unknown')\n",
    "\n",
    "# Check if number of rows of output_df is the same as that of soildata_df\n",
    "# If the number of rows is the same, the merge was successful\n",
    "target = soildata_df.shape[0]\n",
    "print(\n",
    "  '\\nThere should be', target, 'layers:',\n",
    "  target == output_df.shape[0], '\\nThere are', output_df.shape[0], 'layers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Write the output_df to a TXT file\n",
    "# Field separator: tab. Decimal separator: comma\n",
    "file_path = os.path.join(work_dir, 'data', '21_soildata_soc.txt')\n",
    "output_df.to_csv(file_path, sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geemap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
